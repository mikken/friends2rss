#!/usr/bin/python3
"""This script loads LJ cookies and then generates RSS feed from friends page.

Author: Paul Volkov
"""

import sys
import configparser
import urllib.request
import urllib.error
import http.cookiejar
from os.path import abspath, realpath, dirname
from os import chdir

from bs4 import BeautifulSoup

from friendsaux import rss_builder

def open_url():
    """Retreives friends page and returns the response."""
    if not keep_quiet:
        print('opening page', URL)
    try:
        return opener.open(URL)
    except urllib.error.URLError:
        sys.stderr.write('error while loading page\n')
        sys.exit(2)


def find_class(tag, searchtag, searchclass):
    """Returns tag's or soup's subtag with a given class name."""
    return tag.find(searchtag, {'class' : searchclass})


def parse_page(soup, entries):
    """Goes through a page and generates a list with entries."""
    glob_divs = soup.findAll('div', {'class' : 'subcontent'})
    for glob_div_tag in glob_divs:
        entry = rss_builder.Entry()

        font_tag = glob_div_tag.find('font')
        entry.author = font_tag.contents[0]

        datesubject_tag = find_class(glob_div_tag, 'div', 'datesubject')
        date_tag = find_class(datesubject_tag, 'div', 'date')
        entry.date = date_tag.contents[0]
        a_tag = datesubject_tag.find('a')
        entry.subject = a_tag.contents[0]
        protected_tag = datesubject_tag.find('img', alt='[protected post]')
        if (protected_tag):
            entry.subject = protected_prefix + ' ' + entry.subject
        try:
            entry.link = a_tag.attrs['href']
        except KeyError:
            divcomments_tag = find_class(glob_div_tag, 'div', 'comments')
            a_tag = divcomments_tag.find('a')
            corrected = a_tag.attrs['href'] 
            entry.link = corrected[:corrected.find('?')]

        entrytext_tag = find_class(glob_div_tag, 'div', 'entry_text')
        # iframes vary between refetches, we strip them
        for iframe_tag in entrytext_tag.findAll('iframe'):
            iframe_tag.replaceWith('(IFRAME)')
        # remove vk.com's button from reposts for the same reason
        for vk_tag in entrytext_tag.findAll('div',
                {'class' : 'lj-like-item lj-like-item-vkontakte'}):
            vk_tag.replaceWith('')
        entry.text = entrytext_tag.encode('utf-8').decode()
        # need to strip <div> and </div>
        pos = entry.text.find('>')
        entry.text = entry.text[pos + 1:-6]
        entries.append(entry)


def check_logged_state(soup):
    """Checks if we are logged in by analyzing HTML page.

    Returns True in case of a yes."""
    mark_tag = soup.find('input', {'name' : 'user'})
    if (not mark_tag):
        return False
    if 'value' in mark_tag.attrs.keys():
        return True
    else:
        return False


def main():
    """Script entry point"""
    global URL, opener, protected_prefix
    # First, set working directory to current .py's location
    chdir(dirname(realpath(abspath(__file__))))
    # Load config
    try:
        config = configparser.ConfigParser()
        config.read('friends2rss.conf')
        URL = config['global']['URL']
        initialURL = URL
        depth = int(config['global']['depth'])
        protected_prefix = config['global']['protected_prefix']
    except IOError:
        sys.stderr.write('Could not read config file\n')
        sys.exit(3)
    except (KeyError, ValueError):
        sys.stderr.write("Config file isn't sane\n")
        sys.exit(4)
    # Load cookies generated by login script
    jar = http.cookiejar.MozillaCookieJar()
    try:
        jar.load('lj_cookies.txt')
    except IOError:
        sys.stderr.write('Error loading cookies\n')
        sys.exit(1)
    cooker = urllib.request.HTTPCookieProcessor(jar)
    opener = urllib.request.build_opener(cooker)
    response = open_url()
    page = response.read().decode('utf-8')
    soup = BeautifulSoup(page)
    if not check_logged_state(soup):
        sys.stderr.write('Not logged in\n')
        sys.exit(26)
    title = soup.title
    userpic_tag = soup.find('img', alt="Userpic")
    ara_tag = find_class(soup, 'a', 'i-ljuser-username')
    image = {'url' : userpic_tag.attrs['src'], 'link' : ara_tag.attrs['href'], \
            'title' : 'image', 'width' : '100', 'height' : '100'}
    entries = []
    parse_page(soup, entries)
    depth -= 1
    while depth > 0:
        footer_tag = find_class(soup, 'ul', 'navfooter')
        a_tag = footer_tag.find('a')
        try:
            URL = a_tag.attrs['href']
        except AttributeError:
            sys.stderr.write("Couldn't extract next level URL")
            break
        response = open_url()
        soup = BeautifulSoup(response.read().decode('utf-8'))
        parse_page(soup, entries)
        depth -= 1
    rss_feed = rss_builder.build_rss(entries, title, initialURL, \
            'livejournal friends feed', image)
    with open('friends.xml', 'w') as f:
        f.write(rss_feed)


if __name__ == '__main__':
    # Parse argument list
    usage = 'Usage: friend2rss.py [-q]\n\n'
    keep_quiet = False
    for argument in sys.argv[1:]:
        if argument == '-q':
            keep_quiet = True
        else:
            sys.stderr.write(usage)
            sys.exit(25)
    # Execute main procedure
    main()
